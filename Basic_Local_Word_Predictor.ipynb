{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "Words=['forget gate','input gate','input','Overfitting','Overfitting problem']"
      ],
      "metadata": {
        "id": "jBbMGVVMDNtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEiMFP-5F900",
        "outputId": "d141c53f-b9c0-4cd9-f75b-9f1a57be806c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Long ShortTerm Memory LSTM networks are a special kind of Recurrent Neural Network RNN\n",
            "They are designed to overcome the limitations of traditional RNNs especially the vanishing gradient problem\n",
            "LSTMs are particularly useful for sequential data where the order of information is important\n",
            "This includes tasks like time series forecasting natural language processing and speech recognition\n",
            "An LSTM network is composed of memory cells gates and a hidden state\n",
            "The memory cell stores information over time allowing the LSTM to maintain longterm dependencies\n",
            "The gates in an LSTM control the flow of information into and out of the memory cell\n",
            "These gates include the forget gate input gate and output gate\n",
            "The forget gate decides what information to discard from the memory\n",
            "The input gate controls what new information to store in the memory\n",
            "The output gate determines what information to output from the memory cell\n",
            "LSTMs have the advantage of being able to capture longterm dependencies in data which traditional RNNs struggle with\n",
            "This makes them particularly effective for tasks like language modeling where context is crucial\n",
            "In language modeling the LSTM can learn to predict the next word in a sentence based on previous words\n",
            "LSTMs are also used for speech recognition where they can map audio features to text\n",
            "They have been used to achieve stateoftheart results in various fields such as machine translation and sentiment analysis\n",
            "Despite their effectiveness LSTMs have some limitations\n",
            "They are computationally more expensive than traditional RNNs due to their complex architecture\n",
            "Training an LSTM model can require significant computational resources especially for large datasets\n",
            "Overfitting can also be a problem especially when training on small datasets\n",
            "To mitigate overfitting techniques like dropout and regularization are often used\n",
            "While LSTMs are powerful they are not always the best choice for every task\n",
            "In recent years Transformer models which use selfattention mechanisms have gained popularity for certain NLP tasks\n",
            "Transformers have shown superior performance over LSTMs in tasks like machine translation and language understanding\n",
            "Nevertheless LSTMs remain a valuable tool for sequential data processing especially in applications where longterm dependencies are crucial\n",
            "LSTMs continue to be widely used in research and practical applications especially for time series prediction and NLP tasks\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Original text\n",
        "text= \"\"\"Long Short-Term Memory (LSTM) networks are a special kind of Recurrent Neural Network (RNN).\n",
        "They are designed to overcome the limitations of traditional RNNs, especially the vanishing gradient problem.\n",
        "LSTMs are particularly useful for sequential data, where the order of information is important.\n",
        "This includes tasks like time series forecasting, natural language processing, and speech recognition.\n",
        "An LSTM network is composed of memory cells, gates, and a hidden state.\n",
        "The memory cell stores information over time, allowing the LSTM to maintain long-term dependencies.\n",
        "The gates in an LSTM control the flow of information into and out of the memory cell.\n",
        "These gates include the forget gate, input gate, and output gate.\n",
        "The forget gate decides what information to discard from the memory.\n",
        "The input gate controls what new information to store in the memory.\n",
        "The output gate determines what information to output from the memory cell.\n",
        "LSTMs have the advantage of being able to capture long-term dependencies in data, which traditional RNNs struggle with.\n",
        "This makes them particularly effective for tasks like language modeling, where context is crucial.\n",
        "In language modeling, the LSTM can learn to predict the next word in a sentence based on previous words.\n",
        "LSTMs are also used for speech recognition, where they can map audio features to text.\n",
        "They have been used to achieve state-of-the-art results in various fields, such as machine translation and sentiment analysis.\n",
        "Despite their effectiveness, LSTMs have some limitations.\n",
        "They are computationally more expensive than traditional RNNs due to their complex architecture.\n",
        "Training an LSTM model can require significant computational resources, especially for large datasets.\n",
        "Overfitting can also be a problem, especially when training on small datasets.\n",
        "To mitigate overfitting, techniques like dropout and regularization are often used.\n",
        "While LSTMs are powerful, they are not always the best choice for every task.\n",
        "In recent years, Transformer models, which use self-attention mechanisms, have gained popularity for certain NLP tasks.\n",
        "Transformers have shown superior performance over LSTMs in tasks like machine translation and language understanding.\n",
        "Nevertheless, LSTMs remain a valuable tool for sequential data processing, especially in applications where long-term dependencies are crucial.\n",
        "LSTMs continue to be widely used in research and practical applications, especially for time series prediction and NLP tasks.\"\"\"\n",
        "\n",
        "# Preprocessing steps:\n",
        "text = text.strip()  # Remove extra spaces\n",
        "text = re.sub(r'[^A-Za-z0-9\\s]', '', text)  # Remove special characters\n",
        "print(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "NDZDaf3_HEtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=Tokenizer() #Tokenizer Object"
      ],
      "metadata": {
        "id": "pauFTt7zITXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([text])"
      ],
      "metadata": {
        "id": "DoerkCNPIZok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Number of Unique words in the provided text\n",
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYfA2DI2IeE-",
        "outputId": "8e89e495-b74c-4a82-a7f6-d6e9ce9fdd1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "186"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in text.split('\\n'):\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuJH4t86KiFo",
        "outputId": "4fb971cb-0421-49f6-cc85-6a5a7c122e2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Long ShortTerm Memory LSTM networks are a special kind of Recurrent Neural Network RNN\n",
            "They are designed to overcome the limitations of traditional RNNs especially the vanishing gradient problem\n",
            "LSTMs are particularly useful for sequential data where the order of information is important\n",
            "This includes tasks like time series forecasting natural language processing and speech recognition\n",
            "An LSTM network is composed of memory cells gates and a hidden state\n",
            "The memory cell stores information over time allowing the LSTM to maintain longterm dependencies\n",
            "The gates in an LSTM control the flow of information into and out of the memory cell\n",
            "These gates include the forget gate input gate and output gate\n",
            "The forget gate decides what information to discard from the memory\n",
            "The input gate controls what new information to store in the memory\n",
            "The output gate determines what information to output from the memory cell\n",
            "LSTMs have the advantage of being able to capture longterm dependencies in data which traditional RNNs struggle with\n",
            "This makes them particularly effective for tasks like language modeling where context is crucial\n",
            "In language modeling the LSTM can learn to predict the next word in a sentence based on previous words\n",
            "LSTMs are also used for speech recognition where they can map audio features to text\n",
            "They have been used to achieve stateoftheart results in various fields such as machine translation and sentiment analysis\n",
            "Despite their effectiveness LSTMs have some limitations\n",
            "They are computationally more expensive than traditional RNNs due to their complex architecture\n",
            "Training an LSTM model can require significant computational resources especially for large datasets\n",
            "Overfitting can also be a problem especially when training on small datasets\n",
            "To mitigate overfitting techniques like dropout and regularization are often used\n",
            "While LSTMs are powerful they are not always the best choice for every task\n",
            "In recent years Transformer models which use selfattention mechanisms have gained popularity for certain NLP tasks\n",
            "Transformers have shown superior performance over LSTMs in tasks like machine translation and language understanding\n",
            "Nevertheless LSTMs remain a valuable tool for sequential data processing especially in applications where longterm dependencies are crucial\n",
            "LSTMs continue to be widely used in research and practical applications especially for time series prediction and NLP tasks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2nxBrXgzVa_",
        "outputId": "0345d0fa-0b91-4469-884e-1e942d8b2c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'to': 2,\n",
              " 'in': 3,\n",
              " 'are': 4,\n",
              " 'and': 5,\n",
              " 'lstms': 6,\n",
              " 'for': 7,\n",
              " 'memory': 8,\n",
              " 'of': 9,\n",
              " 'lstm': 10,\n",
              " 'information': 11,\n",
              " 'gate': 12,\n",
              " 'a': 13,\n",
              " 'they': 14,\n",
              " 'especially': 15,\n",
              " 'tasks': 16,\n",
              " 'have': 17,\n",
              " 'where': 18,\n",
              " 'like': 19,\n",
              " 'language': 20,\n",
              " 'can': 21,\n",
              " 'used': 22,\n",
              " 'traditional': 23,\n",
              " 'rnns': 24,\n",
              " 'data': 25,\n",
              " 'is': 26,\n",
              " 'time': 27,\n",
              " 'an': 28,\n",
              " 'gates': 29,\n",
              " 'cell': 30,\n",
              " 'longterm': 31,\n",
              " 'dependencies': 32,\n",
              " 'output': 33,\n",
              " 'what': 34,\n",
              " 'network': 35,\n",
              " 'limitations': 36,\n",
              " 'problem': 37,\n",
              " 'particularly': 38,\n",
              " 'sequential': 39,\n",
              " 'this': 40,\n",
              " 'series': 41,\n",
              " 'processing': 42,\n",
              " 'speech': 43,\n",
              " 'recognition': 44,\n",
              " 'over': 45,\n",
              " 'forget': 46,\n",
              " 'input': 47,\n",
              " 'from': 48,\n",
              " 'which': 49,\n",
              " 'modeling': 50,\n",
              " 'crucial': 51,\n",
              " 'on': 52,\n",
              " 'also': 53,\n",
              " 'machine': 54,\n",
              " 'translation': 55,\n",
              " 'their': 56,\n",
              " 'training': 57,\n",
              " 'datasets': 58,\n",
              " 'overfitting': 59,\n",
              " 'be': 60,\n",
              " 'nlp': 61,\n",
              " 'applications': 62,\n",
              " 'long': 63,\n",
              " 'shortterm': 64,\n",
              " 'networks': 65,\n",
              " 'special': 66,\n",
              " 'kind': 67,\n",
              " 'recurrent': 68,\n",
              " 'neural': 69,\n",
              " 'rnn': 70,\n",
              " 'designed': 71,\n",
              " 'overcome': 72,\n",
              " 'vanishing': 73,\n",
              " 'gradient': 74,\n",
              " 'useful': 75,\n",
              " 'order': 76,\n",
              " 'important': 77,\n",
              " 'includes': 78,\n",
              " 'forecasting': 79,\n",
              " 'natural': 80,\n",
              " 'composed': 81,\n",
              " 'cells': 82,\n",
              " 'hidden': 83,\n",
              " 'state': 84,\n",
              " 'stores': 85,\n",
              " 'allowing': 86,\n",
              " 'maintain': 87,\n",
              " 'control': 88,\n",
              " 'flow': 89,\n",
              " 'into': 90,\n",
              " 'out': 91,\n",
              " 'these': 92,\n",
              " 'include': 93,\n",
              " 'decides': 94,\n",
              " 'discard': 95,\n",
              " 'controls': 96,\n",
              " 'new': 97,\n",
              " 'store': 98,\n",
              " 'determines': 99,\n",
              " 'advantage': 100,\n",
              " 'being': 101,\n",
              " 'able': 102,\n",
              " 'capture': 103,\n",
              " 'struggle': 104,\n",
              " 'with': 105,\n",
              " 'makes': 106,\n",
              " 'them': 107,\n",
              " 'effective': 108,\n",
              " 'context': 109,\n",
              " 'learn': 110,\n",
              " 'predict': 111,\n",
              " 'next': 112,\n",
              " 'word': 113,\n",
              " 'sentence': 114,\n",
              " 'based': 115,\n",
              " 'previous': 116,\n",
              " 'words': 117,\n",
              " 'map': 118,\n",
              " 'audio': 119,\n",
              " 'features': 120,\n",
              " 'text': 121,\n",
              " 'been': 122,\n",
              " 'achieve': 123,\n",
              " 'stateoftheart': 124,\n",
              " 'results': 125,\n",
              " 'various': 126,\n",
              " 'fields': 127,\n",
              " 'such': 128,\n",
              " 'as': 129,\n",
              " 'sentiment': 130,\n",
              " 'analysis': 131,\n",
              " 'despite': 132,\n",
              " 'effectiveness': 133,\n",
              " 'some': 134,\n",
              " 'computationally': 135,\n",
              " 'more': 136,\n",
              " 'expensive': 137,\n",
              " 'than': 138,\n",
              " 'due': 139,\n",
              " 'complex': 140,\n",
              " 'architecture': 141,\n",
              " 'model': 142,\n",
              " 'require': 143,\n",
              " 'significant': 144,\n",
              " 'computational': 145,\n",
              " 'resources': 146,\n",
              " 'large': 147,\n",
              " 'when': 148,\n",
              " 'small': 149,\n",
              " 'mitigate': 150,\n",
              " 'techniques': 151,\n",
              " 'dropout': 152,\n",
              " 'regularization': 153,\n",
              " 'often': 154,\n",
              " 'while': 155,\n",
              " 'powerful': 156,\n",
              " 'not': 157,\n",
              " 'always': 158,\n",
              " 'best': 159,\n",
              " 'choice': 160,\n",
              " 'every': 161,\n",
              " 'task': 162,\n",
              " 'recent': 163,\n",
              " 'years': 164,\n",
              " 'transformer': 165,\n",
              " 'models': 166,\n",
              " 'use': 167,\n",
              " 'selfattention': 168,\n",
              " 'mechanisms': 169,\n",
              " 'gained': 170,\n",
              " 'popularity': 171,\n",
              " 'certain': 172,\n",
              " 'transformers': 173,\n",
              " 'shown': 174,\n",
              " 'superior': 175,\n",
              " 'performance': 176,\n",
              " 'understanding': 177,\n",
              " 'nevertheless': 178,\n",
              " 'remain': 179,\n",
              " 'valuable': 180,\n",
              " 'tool': 181,\n",
              " 'continue': 182,\n",
              " 'widely': 183,\n",
              " 'research': 184,\n",
              " 'practical': 185,\n",
              " 'prediction': 186}"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We are creating a dataset where a sequence of words are stored in an non-decreasing manner\n",
        "input_sequence=[]\n",
        "for sentence in text.split('\\n'):\n",
        "  tokennized_sentence=tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1,len(tokennized_sentence)):\n",
        "    n_gram=tokennized_sentence[:i+1]\n",
        "    input_sequence.append(n_gram)"
      ],
      "metadata": {
        "id": "hcMN9G01Ig-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This is how the data will look like\n",
        "input_sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7T8MzPoI16S",
        "outputId": "44bdc3b3-44ea-435c-8892-4fe4decc0522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[63, 64],\n",
              " [63, 64, 8],\n",
              " [63, 64, 8, 10],\n",
              " [63, 64, 8, 10, 65],\n",
              " [63, 64, 8, 10, 65, 4],\n",
              " [63, 64, 8, 10, 65, 4, 13],\n",
              " [63, 64, 8, 10, 65, 4, 13, 66],\n",
              " [63, 64, 8, 10, 65, 4, 13, 66, 67],\n",
              " [63, 64, 8, 10, 65, 4, 13, 66, 67, 9],\n",
              " [63, 64, 8, 10, 65, 4, 13, 66, 67, 9, 68],\n",
              " [63, 64, 8, 10, 65, 4, 13, 66, 67, 9, 68, 69],\n",
              " [63, 64, 8, 10, 65, 4, 13, 66, 67, 9, 68, 69, 35],\n",
              " [63, 64, 8, 10, 65, 4, 13, 66, 67, 9, 68, 69, 35, 70],\n",
              " [14, 4],\n",
              " [14, 4, 71],\n",
              " [14, 4, 71, 2],\n",
              " [14, 4, 71, 2, 72],\n",
              " [14, 4, 71, 2, 72, 1],\n",
              " [14, 4, 71, 2, 72, 1, 36],\n",
              " [14, 4, 71, 2, 72, 1, 36, 9],\n",
              " [14, 4, 71, 2, 72, 1, 36, 9, 23],\n",
              " [14, 4, 71, 2, 72, 1, 36, 9, 23, 24],\n",
              " [14, 4, 71, 2, 72, 1, 36, 9, 23, 24, 15],\n",
              " [14, 4, 71, 2, 72, 1, 36, 9, 23, 24, 15, 1],\n",
              " [14, 4, 71, 2, 72, 1, 36, 9, 23, 24, 15, 1, 73],\n",
              " [14, 4, 71, 2, 72, 1, 36, 9, 23, 24, 15, 1, 73, 74],\n",
              " [14, 4, 71, 2, 72, 1, 36, 9, 23, 24, 15, 1, 73, 74, 37],\n",
              " [6, 4],\n",
              " [6, 4, 38],\n",
              " [6, 4, 38, 75],\n",
              " [6, 4, 38, 75, 7],\n",
              " [6, 4, 38, 75, 7, 39],\n",
              " [6, 4, 38, 75, 7, 39, 25],\n",
              " [6, 4, 38, 75, 7, 39, 25, 18],\n",
              " [6, 4, 38, 75, 7, 39, 25, 18, 1],\n",
              " [6, 4, 38, 75, 7, 39, 25, 18, 1, 76],\n",
              " [6, 4, 38, 75, 7, 39, 25, 18, 1, 76, 9],\n",
              " [6, 4, 38, 75, 7, 39, 25, 18, 1, 76, 9, 11],\n",
              " [6, 4, 38, 75, 7, 39, 25, 18, 1, 76, 9, 11, 26],\n",
              " [6, 4, 38, 75, 7, 39, 25, 18, 1, 76, 9, 11, 26, 77],\n",
              " [40, 78],\n",
              " [40, 78, 16],\n",
              " [40, 78, 16, 19],\n",
              " [40, 78, 16, 19, 27],\n",
              " [40, 78, 16, 19, 27, 41],\n",
              " [40, 78, 16, 19, 27, 41, 79],\n",
              " [40, 78, 16, 19, 27, 41, 79, 80],\n",
              " [40, 78, 16, 19, 27, 41, 79, 80, 20],\n",
              " [40, 78, 16, 19, 27, 41, 79, 80, 20, 42],\n",
              " [40, 78, 16, 19, 27, 41, 79, 80, 20, 42, 5],\n",
              " [40, 78, 16, 19, 27, 41, 79, 80, 20, 42, 5, 43],\n",
              " [40, 78, 16, 19, 27, 41, 79, 80, 20, 42, 5, 43, 44],\n",
              " [28, 10],\n",
              " [28, 10, 35],\n",
              " [28, 10, 35, 26],\n",
              " [28, 10, 35, 26, 81],\n",
              " [28, 10, 35, 26, 81, 9],\n",
              " [28, 10, 35, 26, 81, 9, 8],\n",
              " [28, 10, 35, 26, 81, 9, 8, 82],\n",
              " [28, 10, 35, 26, 81, 9, 8, 82, 29],\n",
              " [28, 10, 35, 26, 81, 9, 8, 82, 29, 5],\n",
              " [28, 10, 35, 26, 81, 9, 8, 82, 29, 5, 13],\n",
              " [28, 10, 35, 26, 81, 9, 8, 82, 29, 5, 13, 83],\n",
              " [28, 10, 35, 26, 81, 9, 8, 82, 29, 5, 13, 83, 84],\n",
              " [1, 8],\n",
              " [1, 8, 30],\n",
              " [1, 8, 30, 85],\n",
              " [1, 8, 30, 85, 11],\n",
              " [1, 8, 30, 85, 11, 45],\n",
              " [1, 8, 30, 85, 11, 45, 27],\n",
              " [1, 8, 30, 85, 11, 45, 27, 86],\n",
              " [1, 8, 30, 85, 11, 45, 27, 86, 1],\n",
              " [1, 8, 30, 85, 11, 45, 27, 86, 1, 10],\n",
              " [1, 8, 30, 85, 11, 45, 27, 86, 1, 10, 2],\n",
              " [1, 8, 30, 85, 11, 45, 27, 86, 1, 10, 2, 87],\n",
              " [1, 8, 30, 85, 11, 45, 27, 86, 1, 10, 2, 87, 31],\n",
              " [1, 8, 30, 85, 11, 45, 27, 86, 1, 10, 2, 87, 31, 32],\n",
              " [1, 29],\n",
              " [1, 29, 3],\n",
              " [1, 29, 3, 28],\n",
              " [1, 29, 3, 28, 10],\n",
              " [1, 29, 3, 28, 10, 88],\n",
              " [1, 29, 3, 28, 10, 88, 1],\n",
              " [1, 29, 3, 28, 10, 88, 1, 89],\n",
              " [1, 29, 3, 28, 10, 88, 1, 89, 9],\n",
              " [1, 29, 3, 28, 10, 88, 1, 89, 9, 11],\n",
              " [1, 29, 3, 28, 10, 88, 1, 89, 9, 11, 90],\n",
              " [1, 29, 3, 28, 10, 88, 1, 89, 9, 11, 90, 5],\n",
              " [1, 29, 3, 28, 10, 88, 1, 89, 9, 11, 90, 5, 91],\n",
              " [1, 29, 3, 28, 10, 88, 1, 89, 9, 11, 90, 5, 91, 9],\n",
              " [1, 29, 3, 28, 10, 88, 1, 89, 9, 11, 90, 5, 91, 9, 1],\n",
              " [1, 29, 3, 28, 10, 88, 1, 89, 9, 11, 90, 5, 91, 9, 1, 8],\n",
              " [1, 29, 3, 28, 10, 88, 1, 89, 9, 11, 90, 5, 91, 9, 1, 8, 30],\n",
              " [92, 29],\n",
              " [92, 29, 93],\n",
              " [92, 29, 93, 1],\n",
              " [92, 29, 93, 1, 46],\n",
              " [92, 29, 93, 1, 46, 12],\n",
              " [92, 29, 93, 1, 46, 12, 47],\n",
              " [92, 29, 93, 1, 46, 12, 47, 12],\n",
              " [92, 29, 93, 1, 46, 12, 47, 12, 5],\n",
              " [92, 29, 93, 1, 46, 12, 47, 12, 5, 33],\n",
              " [92, 29, 93, 1, 46, 12, 47, 12, 5, 33, 12],\n",
              " [1, 46],\n",
              " [1, 46, 12],\n",
              " [1, 46, 12, 94],\n",
              " [1, 46, 12, 94, 34],\n",
              " [1, 46, 12, 94, 34, 11],\n",
              " [1, 46, 12, 94, 34, 11, 2],\n",
              " [1, 46, 12, 94, 34, 11, 2, 95],\n",
              " [1, 46, 12, 94, 34, 11, 2, 95, 48],\n",
              " [1, 46, 12, 94, 34, 11, 2, 95, 48, 1],\n",
              " [1, 46, 12, 94, 34, 11, 2, 95, 48, 1, 8],\n",
              " [1, 47],\n",
              " [1, 47, 12],\n",
              " [1, 47, 12, 96],\n",
              " [1, 47, 12, 96, 34],\n",
              " [1, 47, 12, 96, 34, 97],\n",
              " [1, 47, 12, 96, 34, 97, 11],\n",
              " [1, 47, 12, 96, 34, 97, 11, 2],\n",
              " [1, 47, 12, 96, 34, 97, 11, 2, 98],\n",
              " [1, 47, 12, 96, 34, 97, 11, 2, 98, 3],\n",
              " [1, 47, 12, 96, 34, 97, 11, 2, 98, 3, 1],\n",
              " [1, 47, 12, 96, 34, 97, 11, 2, 98, 3, 1, 8],\n",
              " [1, 33],\n",
              " [1, 33, 12],\n",
              " [1, 33, 12, 99],\n",
              " [1, 33, 12, 99, 34],\n",
              " [1, 33, 12, 99, 34, 11],\n",
              " [1, 33, 12, 99, 34, 11, 2],\n",
              " [1, 33, 12, 99, 34, 11, 2, 33],\n",
              " [1, 33, 12, 99, 34, 11, 2, 33, 48],\n",
              " [1, 33, 12, 99, 34, 11, 2, 33, 48, 1],\n",
              " [1, 33, 12, 99, 34, 11, 2, 33, 48, 1, 8],\n",
              " [1, 33, 12, 99, 34, 11, 2, 33, 48, 1, 8, 30],\n",
              " [6, 17],\n",
              " [6, 17, 1],\n",
              " [6, 17, 1, 100],\n",
              " [6, 17, 1, 100, 9],\n",
              " [6, 17, 1, 100, 9, 101],\n",
              " [6, 17, 1, 100, 9, 101, 102],\n",
              " [6, 17, 1, 100, 9, 101, 102, 2],\n",
              " [6, 17, 1, 100, 9, 101, 102, 2, 103],\n",
              " [6, 17, 1, 100, 9, 101, 102, 2, 103, 31],\n",
              " [6, 17, 1, 100, 9, 101, 102, 2, 103, 31, 32],\n",
              " [6, 17, 1, 100, 9, 101, 102, 2, 103, 31, 32, 3],\n",
              " [6, 17, 1, 100, 9, 101, 102, 2, 103, 31, 32, 3, 25],\n",
              " [6, 17, 1, 100, 9, 101, 102, 2, 103, 31, 32, 3, 25, 49],\n",
              " [6, 17, 1, 100, 9, 101, 102, 2, 103, 31, 32, 3, 25, 49, 23],\n",
              " [6, 17, 1, 100, 9, 101, 102, 2, 103, 31, 32, 3, 25, 49, 23, 24],\n",
              " [6, 17, 1, 100, 9, 101, 102, 2, 103, 31, 32, 3, 25, 49, 23, 24, 104],\n",
              " [6, 17, 1, 100, 9, 101, 102, 2, 103, 31, 32, 3, 25, 49, 23, 24, 104, 105],\n",
              " [40, 106],\n",
              " [40, 106, 107],\n",
              " [40, 106, 107, 38],\n",
              " [40, 106, 107, 38, 108],\n",
              " [40, 106, 107, 38, 108, 7],\n",
              " [40, 106, 107, 38, 108, 7, 16],\n",
              " [40, 106, 107, 38, 108, 7, 16, 19],\n",
              " [40, 106, 107, 38, 108, 7, 16, 19, 20],\n",
              " [40, 106, 107, 38, 108, 7, 16, 19, 20, 50],\n",
              " [40, 106, 107, 38, 108, 7, 16, 19, 20, 50, 18],\n",
              " [40, 106, 107, 38, 108, 7, 16, 19, 20, 50, 18, 109],\n",
              " [40, 106, 107, 38, 108, 7, 16, 19, 20, 50, 18, 109, 26],\n",
              " [40, 106, 107, 38, 108, 7, 16, 19, 20, 50, 18, 109, 26, 51],\n",
              " [3, 20],\n",
              " [3, 20, 50],\n",
              " [3, 20, 50, 1],\n",
              " [3, 20, 50, 1, 10],\n",
              " [3, 20, 50, 1, 10, 21],\n",
              " [3, 20, 50, 1, 10, 21, 110],\n",
              " [3, 20, 50, 1, 10, 21, 110, 2],\n",
              " [3, 20, 50, 1, 10, 21, 110, 2, 111],\n",
              " [3, 20, 50, 1, 10, 21, 110, 2, 111, 1],\n",
              " [3, 20, 50, 1, 10, 21, 110, 2, 111, 1, 112],\n",
              " [3, 20, 50, 1, 10, 21, 110, 2, 111, 1, 112, 113],\n",
              " [3, 20, 50, 1, 10, 21, 110, 2, 111, 1, 112, 113, 3],\n",
              " [3, 20, 50, 1, 10, 21, 110, 2, 111, 1, 112, 113, 3, 13],\n",
              " [3, 20, 50, 1, 10, 21, 110, 2, 111, 1, 112, 113, 3, 13, 114],\n",
              " [3, 20, 50, 1, 10, 21, 110, 2, 111, 1, 112, 113, 3, 13, 114, 115],\n",
              " [3, 20, 50, 1, 10, 21, 110, 2, 111, 1, 112, 113, 3, 13, 114, 115, 52],\n",
              " [3, 20, 50, 1, 10, 21, 110, 2, 111, 1, 112, 113, 3, 13, 114, 115, 52, 116],\n",
              " [3,\n",
              "  20,\n",
              "  50,\n",
              "  1,\n",
              "  10,\n",
              "  21,\n",
              "  110,\n",
              "  2,\n",
              "  111,\n",
              "  1,\n",
              "  112,\n",
              "  113,\n",
              "  3,\n",
              "  13,\n",
              "  114,\n",
              "  115,\n",
              "  52,\n",
              "  116,\n",
              "  117],\n",
              " [6, 4],\n",
              " [6, 4, 53],\n",
              " [6, 4, 53, 22],\n",
              " [6, 4, 53, 22, 7],\n",
              " [6, 4, 53, 22, 7, 43],\n",
              " [6, 4, 53, 22, 7, 43, 44],\n",
              " [6, 4, 53, 22, 7, 43, 44, 18],\n",
              " [6, 4, 53, 22, 7, 43, 44, 18, 14],\n",
              " [6, 4, 53, 22, 7, 43, 44, 18, 14, 21],\n",
              " [6, 4, 53, 22, 7, 43, 44, 18, 14, 21, 118],\n",
              " [6, 4, 53, 22, 7, 43, 44, 18, 14, 21, 118, 119],\n",
              " [6, 4, 53, 22, 7, 43, 44, 18, 14, 21, 118, 119, 120],\n",
              " [6, 4, 53, 22, 7, 43, 44, 18, 14, 21, 118, 119, 120, 2],\n",
              " [6, 4, 53, 22, 7, 43, 44, 18, 14, 21, 118, 119, 120, 2, 121],\n",
              " [14, 17],\n",
              " [14, 17, 122],\n",
              " [14, 17, 122, 22],\n",
              " [14, 17, 122, 22, 2],\n",
              " [14, 17, 122, 22, 2, 123],\n",
              " [14, 17, 122, 22, 2, 123, 124],\n",
              " [14, 17, 122, 22, 2, 123, 124, 125],\n",
              " [14, 17, 122, 22, 2, 123, 124, 125, 3],\n",
              " [14, 17, 122, 22, 2, 123, 124, 125, 3, 126],\n",
              " [14, 17, 122, 22, 2, 123, 124, 125, 3, 126, 127],\n",
              " [14, 17, 122, 22, 2, 123, 124, 125, 3, 126, 127, 128],\n",
              " [14, 17, 122, 22, 2, 123, 124, 125, 3, 126, 127, 128, 129],\n",
              " [14, 17, 122, 22, 2, 123, 124, 125, 3, 126, 127, 128, 129, 54],\n",
              " [14, 17, 122, 22, 2, 123, 124, 125, 3, 126, 127, 128, 129, 54, 55],\n",
              " [14, 17, 122, 22, 2, 123, 124, 125, 3, 126, 127, 128, 129, 54, 55, 5],\n",
              " [14, 17, 122, 22, 2, 123, 124, 125, 3, 126, 127, 128, 129, 54, 55, 5, 130],\n",
              " [14,\n",
              "  17,\n",
              "  122,\n",
              "  22,\n",
              "  2,\n",
              "  123,\n",
              "  124,\n",
              "  125,\n",
              "  3,\n",
              "  126,\n",
              "  127,\n",
              "  128,\n",
              "  129,\n",
              "  54,\n",
              "  55,\n",
              "  5,\n",
              "  130,\n",
              "  131],\n",
              " [132, 56],\n",
              " [132, 56, 133],\n",
              " [132, 56, 133, 6],\n",
              " [132, 56, 133, 6, 17],\n",
              " [132, 56, 133, 6, 17, 134],\n",
              " [132, 56, 133, 6, 17, 134, 36],\n",
              " [14, 4],\n",
              " [14, 4, 135],\n",
              " [14, 4, 135, 136],\n",
              " [14, 4, 135, 136, 137],\n",
              " [14, 4, 135, 136, 137, 138],\n",
              " [14, 4, 135, 136, 137, 138, 23],\n",
              " [14, 4, 135, 136, 137, 138, 23, 24],\n",
              " [14, 4, 135, 136, 137, 138, 23, 24, 139],\n",
              " [14, 4, 135, 136, 137, 138, 23, 24, 139, 2],\n",
              " [14, 4, 135, 136, 137, 138, 23, 24, 139, 2, 56],\n",
              " [14, 4, 135, 136, 137, 138, 23, 24, 139, 2, 56, 140],\n",
              " [14, 4, 135, 136, 137, 138, 23, 24, 139, 2, 56, 140, 141],\n",
              " [57, 28],\n",
              " [57, 28, 10],\n",
              " [57, 28, 10, 142],\n",
              " [57, 28, 10, 142, 21],\n",
              " [57, 28, 10, 142, 21, 143],\n",
              " [57, 28, 10, 142, 21, 143, 144],\n",
              " [57, 28, 10, 142, 21, 143, 144, 145],\n",
              " [57, 28, 10, 142, 21, 143, 144, 145, 146],\n",
              " [57, 28, 10, 142, 21, 143, 144, 145, 146, 15],\n",
              " [57, 28, 10, 142, 21, 143, 144, 145, 146, 15, 7],\n",
              " [57, 28, 10, 142, 21, 143, 144, 145, 146, 15, 7, 147],\n",
              " [57, 28, 10, 142, 21, 143, 144, 145, 146, 15, 7, 147, 58],\n",
              " [59, 21],\n",
              " [59, 21, 53],\n",
              " [59, 21, 53, 60],\n",
              " [59, 21, 53, 60, 13],\n",
              " [59, 21, 53, 60, 13, 37],\n",
              " [59, 21, 53, 60, 13, 37, 15],\n",
              " [59, 21, 53, 60, 13, 37, 15, 148],\n",
              " [59, 21, 53, 60, 13, 37, 15, 148, 57],\n",
              " [59, 21, 53, 60, 13, 37, 15, 148, 57, 52],\n",
              " [59, 21, 53, 60, 13, 37, 15, 148, 57, 52, 149],\n",
              " [59, 21, 53, 60, 13, 37, 15, 148, 57, 52, 149, 58],\n",
              " [2, 150],\n",
              " [2, 150, 59],\n",
              " [2, 150, 59, 151],\n",
              " [2, 150, 59, 151, 19],\n",
              " [2, 150, 59, 151, 19, 152],\n",
              " [2, 150, 59, 151, 19, 152, 5],\n",
              " [2, 150, 59, 151, 19, 152, 5, 153],\n",
              " [2, 150, 59, 151, 19, 152, 5, 153, 4],\n",
              " [2, 150, 59, 151, 19, 152, 5, 153, 4, 154],\n",
              " [2, 150, 59, 151, 19, 152, 5, 153, 4, 154, 22],\n",
              " [155, 6],\n",
              " [155, 6, 4],\n",
              " [155, 6, 4, 156],\n",
              " [155, 6, 4, 156, 14],\n",
              " [155, 6, 4, 156, 14, 4],\n",
              " [155, 6, 4, 156, 14, 4, 157],\n",
              " [155, 6, 4, 156, 14, 4, 157, 158],\n",
              " [155, 6, 4, 156, 14, 4, 157, 158, 1],\n",
              " [155, 6, 4, 156, 14, 4, 157, 158, 1, 159],\n",
              " [155, 6, 4, 156, 14, 4, 157, 158, 1, 159, 160],\n",
              " [155, 6, 4, 156, 14, 4, 157, 158, 1, 159, 160, 7],\n",
              " [155, 6, 4, 156, 14, 4, 157, 158, 1, 159, 160, 7, 161],\n",
              " [155, 6, 4, 156, 14, 4, 157, 158, 1, 159, 160, 7, 161, 162],\n",
              " [3, 163],\n",
              " [3, 163, 164],\n",
              " [3, 163, 164, 165],\n",
              " [3, 163, 164, 165, 166],\n",
              " [3, 163, 164, 165, 166, 49],\n",
              " [3, 163, 164, 165, 166, 49, 167],\n",
              " [3, 163, 164, 165, 166, 49, 167, 168],\n",
              " [3, 163, 164, 165, 166, 49, 167, 168, 169],\n",
              " [3, 163, 164, 165, 166, 49, 167, 168, 169, 17],\n",
              " [3, 163, 164, 165, 166, 49, 167, 168, 169, 17, 170],\n",
              " [3, 163, 164, 165, 166, 49, 167, 168, 169, 17, 170, 171],\n",
              " [3, 163, 164, 165, 166, 49, 167, 168, 169, 17, 170, 171, 7],\n",
              " [3, 163, 164, 165, 166, 49, 167, 168, 169, 17, 170, 171, 7, 172],\n",
              " [3, 163, 164, 165, 166, 49, 167, 168, 169, 17, 170, 171, 7, 172, 61],\n",
              " [3, 163, 164, 165, 166, 49, 167, 168, 169, 17, 170, 171, 7, 172, 61, 16],\n",
              " [173, 17],\n",
              " [173, 17, 174],\n",
              " [173, 17, 174, 175],\n",
              " [173, 17, 174, 175, 176],\n",
              " [173, 17, 174, 175, 176, 45],\n",
              " [173, 17, 174, 175, 176, 45, 6],\n",
              " [173, 17, 174, 175, 176, 45, 6, 3],\n",
              " [173, 17, 174, 175, 176, 45, 6, 3, 16],\n",
              " [173, 17, 174, 175, 176, 45, 6, 3, 16, 19],\n",
              " [173, 17, 174, 175, 176, 45, 6, 3, 16, 19, 54],\n",
              " [173, 17, 174, 175, 176, 45, 6, 3, 16, 19, 54, 55],\n",
              " [173, 17, 174, 175, 176, 45, 6, 3, 16, 19, 54, 55, 5],\n",
              " [173, 17, 174, 175, 176, 45, 6, 3, 16, 19, 54, 55, 5, 20],\n",
              " [173, 17, 174, 175, 176, 45, 6, 3, 16, 19, 54, 55, 5, 20, 177],\n",
              " [178, 6],\n",
              " [178, 6, 179],\n",
              " [178, 6, 179, 13],\n",
              " [178, 6, 179, 13, 180],\n",
              " [178, 6, 179, 13, 180, 181],\n",
              " [178, 6, 179, 13, 180, 181, 7],\n",
              " [178, 6, 179, 13, 180, 181, 7, 39],\n",
              " [178, 6, 179, 13, 180, 181, 7, 39, 25],\n",
              " [178, 6, 179, 13, 180, 181, 7, 39, 25, 42],\n",
              " [178, 6, 179, 13, 180, 181, 7, 39, 25, 42, 15],\n",
              " [178, 6, 179, 13, 180, 181, 7, 39, 25, 42, 15, 3],\n",
              " [178, 6, 179, 13, 180, 181, 7, 39, 25, 42, 15, 3, 62],\n",
              " [178, 6, 179, 13, 180, 181, 7, 39, 25, 42, 15, 3, 62, 18],\n",
              " [178, 6, 179, 13, 180, 181, 7, 39, 25, 42, 15, 3, 62, 18, 31],\n",
              " [178, 6, 179, 13, 180, 181, 7, 39, 25, 42, 15, 3, 62, 18, 31, 32],\n",
              " [178, 6, 179, 13, 180, 181, 7, 39, 25, 42, 15, 3, 62, 18, 31, 32, 4],\n",
              " [178, 6, 179, 13, 180, 181, 7, 39, 25, 42, 15, 3, 62, 18, 31, 32, 4, 51],\n",
              " [6, 182],\n",
              " [6, 182, 2],\n",
              " [6, 182, 2, 60],\n",
              " [6, 182, 2, 60, 183],\n",
              " [6, 182, 2, 60, 183, 22],\n",
              " [6, 182, 2, 60, 183, 22, 3],\n",
              " [6, 182, 2, 60, 183, 22, 3, 184],\n",
              " [6, 182, 2, 60, 183, 22, 3, 184, 5],\n",
              " [6, 182, 2, 60, 183, 22, 3, 184, 5, 185],\n",
              " [6, 182, 2, 60, 183, 22, 3, 184, 5, 185, 62],\n",
              " [6, 182, 2, 60, 183, 22, 3, 184, 5, 185, 62, 15],\n",
              " [6, 182, 2, 60, 183, 22, 3, 184, 5, 185, 62, 15, 7],\n",
              " [6, 182, 2, 60, 183, 22, 3, 184, 5, 185, 62, 15, 7, 27],\n",
              " [6, 182, 2, 60, 183, 22, 3, 184, 5, 185, 62, 15, 7, 27, 41],\n",
              " [6, 182, 2, 60, 183, 22, 3, 184, 5, 185, 62, 15, 7, 27, 41, 186],\n",
              " [6, 182, 2, 60, 183, 22, 3, 184, 5, 185, 62, 15, 7, 27, 41, 186, 5],\n",
              " [6, 182, 2, 60, 183, 22, 3, 184, 5, 185, 62, 15, 7, 27, 41, 186, 5, 61],\n",
              " [6, 182, 2, 60, 183, 22, 3, 184, 5, 185, 62, 15, 7, 27, 41, 186, 5, 61, 16]]"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Maximum length of a row to pad the entire data\n",
        "max_len=max([len(x) for x in input_sequence])"
      ],
      "metadata": {
        "id": "LeXXFSk9O96E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0zKFRJBbZKT",
        "outputId": "fc320d23-c920-4782-89ad-ca763697b601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "#Padding the input sequence\n",
        "padded_input_sequence=pad_sequences(input_sequence,maxlen=max_len,padding='pre')"
      ],
      "metadata": {
        "id": "8UJdUdkrS_o6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4de3_WITqKv",
        "outputId": "73fb7842-4508-4ea9-9133-44cf637a66c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,  63,  64],\n",
              "       [  0,   0,   0, ...,  63,  64,   8],\n",
              "       [  0,   0,   0, ...,  64,   8,  10],\n",
              "       ...,\n",
              "       [  0,   0,   6, ...,  41, 186,   5],\n",
              "       [  0,   6, 182, ..., 186,   5,  61],\n",
              "       [  6, 182,   2, ...,   5,  61,  16]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dividing the data into Input and Output Columns\n",
        "\"\"\"\n",
        "For the sentence: Deep learning is powerful\n",
        "\n",
        "Input Sequence\t    Output Word\n",
        "Deep\t              learning\n",
        "Deep learning\t      is\n",
        "Deep learning is\t  powerful\n",
        "These pairs serve as labeled data for training the model\n",
        "\"\"\"\n",
        "X=padded_input_sequence[:,:-1]\n",
        "y=padded_input_sequence[:,-1]"
      ],
      "metadata": {
        "id": "TQrqa4fDTtM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "#Applying categorical transformation to make it a multiclass classification problem\n",
        "y=to_categorical(y,num_classes=len(tokenizer.word_index)+1)"
      ],
      "metadata": {
        "id": "CZU-ctKiUWJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1WzEzqsZ-GB",
        "outputId": "b8af1949-09d5-458e-f929-55884470530b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,LSTM,Dense"
      ],
      "metadata": {
        "id": "kDJPdCqsZ_FY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JRhUJCsdcYr",
        "outputId": "53a5bfa9-b225-4f97-b3dd-c17b9464a2a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "187"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "#The Embedding layer in neural networks is used to convert categorical data (like words) into dense vector representations\n",
        "model.add(Embedding(len(tokenizer.word_index)+1,output_dim=100,input_length=max_len))\n",
        "#We are initially getting good results in 268 units in the ANN layer for the LSTM layer\n",
        "model.add(LSTM(286))\n",
        "#Dense Layer for Multiclass classification\n",
        "model.add(Dense(len(tokenizer.word_index)+1,activation='softmax'))"
      ],
      "metadata": {
        "id": "7NR0Az1Abbr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adam and rmsprop are the best optimizers , I used adam\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "liyrxWyIb5Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrwRjqM2wvjM",
        "outputId": "6fe9595c-40bf-4ade-ddbe-ad77c1e14797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 95ms/step - accuracy: 0.0108 - loss: 5.2256\n",
            "Epoch 2/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.0429 - loss: 5.0191\n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.0387 - loss: 4.9153\n",
            "Epoch 4/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.0399 - loss: 4.8098\n",
            "Epoch 5/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.0485 - loss: 4.7689\n",
            "Epoch 6/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.0321 - loss: 4.7675\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.0630 - loss: 4.6187\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.0661 - loss: 4.5440\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.0667 - loss: 4.3706\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.0727 - loss: 4.3389\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.0750 - loss: 4.1863\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.1149 - loss: 4.0211\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.0998 - loss: 3.9251\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.1679 - loss: 3.5471\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.2114 - loss: 3.4428\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.1887 - loss: 3.3477\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.2407 - loss: 3.1104\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.2529 - loss: 2.9552\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.3281 - loss: 2.7646\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.3619 - loss: 2.6498\n",
            "Epoch 21/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.4254 - loss: 2.4026\n",
            "Epoch 22/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4687 - loss: 2.2584\n",
            "Epoch 23/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5512 - loss: 2.1423\n",
            "Epoch 24/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 143ms/step - accuracy: 0.5424 - loss: 2.0646\n",
            "Epoch 25/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.6179 - loss: 1.7906\n",
            "Epoch 26/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.6863 - loss: 1.7132\n",
            "Epoch 27/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.6675 - loss: 1.6323\n",
            "Epoch 28/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step - accuracy: 0.7295 - loss: 1.4829\n",
            "Epoch 29/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.7636 - loss: 1.3491\n",
            "Epoch 30/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.7423 - loss: 1.3214\n",
            "Epoch 31/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7823 - loss: 1.2263\n",
            "Epoch 32/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.7882 - loss: 1.1341\n",
            "Epoch 33/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.8110 - loss: 1.1220\n",
            "Epoch 34/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.8349 - loss: 1.0317\n",
            "Epoch 35/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.8989 - loss: 0.8469\n",
            "Epoch 36/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.9112 - loss: 0.8011\n",
            "Epoch 37/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.8985 - loss: 0.7875\n",
            "Epoch 38/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 0.9235 - loss: 0.7086\n",
            "Epoch 39/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.9051 - loss: 0.7589\n",
            "Epoch 40/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9020 - loss: 0.6879\n",
            "Epoch 41/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9375 - loss: 0.6080\n",
            "Epoch 42/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9108 - loss: 0.6239\n",
            "Epoch 43/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.9535 - loss: 0.5430\n",
            "Epoch 44/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9647 - loss: 0.5071\n",
            "Epoch 45/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.9342 - loss: 0.4877\n",
            "Epoch 46/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9550 - loss: 0.4402\n",
            "Epoch 47/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9429 - loss: 0.4312\n",
            "Epoch 48/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 145ms/step - accuracy: 0.9544 - loss: 0.3781\n",
            "Epoch 49/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 145ms/step - accuracy: 0.9627 - loss: 0.3691\n",
            "Epoch 50/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.9395 - loss: 0.3747\n",
            "Epoch 51/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9688 - loss: 0.3467\n",
            "Epoch 52/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.9490 - loss: 0.3503\n",
            "Epoch 53/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9645 - loss: 0.3204\n",
            "Epoch 54/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.9576 - loss: 0.2911\n",
            "Epoch 55/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9604 - loss: 0.2913\n",
            "Epoch 56/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9486 - loss: 0.2984\n",
            "Epoch 57/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9699 - loss: 0.2411\n",
            "Epoch 58/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9745 - loss: 0.2402\n",
            "Epoch 59/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.9449 - loss: 0.2418\n",
            "Epoch 60/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - accuracy: 0.9583 - loss: 0.2297\n",
            "Epoch 61/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 145ms/step - accuracy: 0.9728 - loss: 0.2189\n",
            "Epoch 62/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9654 - loss: 0.2160\n",
            "Epoch 63/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.9718 - loss: 0.2052\n",
            "Epoch 64/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9639 - loss: 0.2107\n",
            "Epoch 65/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9577 - loss: 0.1861\n",
            "Epoch 66/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.9645 - loss: 0.1806\n",
            "Epoch 67/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9661 - loss: 0.1784\n",
            "Epoch 68/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.9600 - loss: 0.1788\n",
            "Epoch 69/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.9660 - loss: 0.1630\n",
            "Epoch 70/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9638 - loss: 0.1647\n",
            "Epoch 71/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 0.9648 - loss: 0.1643\n",
            "Epoch 72/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.9692 - loss: 0.1467\n",
            "Epoch 73/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9635 - loss: 0.1435\n",
            "Epoch 74/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9780 - loss: 0.1397\n",
            "Epoch 75/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9579 - loss: 0.1514\n",
            "Epoch 76/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.9579 - loss: 0.1542\n",
            "Epoch 77/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9617 - loss: 0.1572\n",
            "Epoch 78/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.9755 - loss: 0.1526\n",
            "Epoch 79/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.9544 - loss: 0.1739\n",
            "Epoch 80/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.9609 - loss: 0.1467\n",
            "Epoch 81/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.9661 - loss: 0.1512\n",
            "Epoch 82/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.9641 - loss: 0.1468\n",
            "Epoch 83/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.9737 - loss: 0.1209\n",
            "Epoch 84/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.9640 - loss: 0.1164\n",
            "Epoch 85/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.9703 - loss: 0.1082\n",
            "Epoch 86/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.9736 - loss: 0.1113\n",
            "Epoch 87/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.9753 - loss: 0.1104\n",
            "Epoch 88/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.9492 - loss: 0.1333\n",
            "Epoch 89/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.9722 - loss: 0.1084\n",
            "Epoch 90/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.9735 - loss: 0.0979\n",
            "Epoch 91/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 142ms/step - accuracy: 0.9620 - loss: 0.0987\n",
            "Epoch 92/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9598 - loss: 0.1279\n",
            "Epoch 93/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9651 - loss: 0.0947\n",
            "Epoch 94/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.9645 - loss: 0.1087\n",
            "Epoch 95/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9711 - loss: 0.0768\n",
            "Epoch 96/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9731 - loss: 0.0781\n",
            "Epoch 97/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9654 - loss: 0.0890\n",
            "Epoch 98/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9617 - loss: 0.1027\n",
            "Epoch 99/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.9776 - loss: 0.0909\n",
            "Epoch 100/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.9572 - loss: 0.1154\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79b0be77f5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Basic testing\n",
        "text=\"LSTM\"\n",
        "for i in range(20):\n",
        "  #tokenize\n",
        "  token_text=tokenizer.texts_to_sequences([text])\n",
        "  #token_text[0]\n",
        "  #Padding\n",
        "  padded_token_text=pad_sequences(token_text,maxlen=max_len,padding='pre')\n",
        "  #padded_token_text\n",
        "  #Predict\n",
        "  arg=np.argmax(model.predict(padded_token_text)[0])\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index==arg:\n",
        "      text=text+' '+word\n",
        "      print(text)\n",
        "      break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3V8TPSXw8XQ",
        "outputId": "231347c7-19a2-430b-aff8-d3c99f5c9715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step\n",
            "LSTM can\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "LSTM can also\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "LSTM can also be\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
            "LSTM can also be a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "LSTM can also be a problem\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
            "LSTM can also be a problem especially\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
            "LSTM can also be a problem especially when\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
            "LSTM can also be a problem especially when training\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
            "LSTM can also be a problem especially when training on\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
            "LSTM can also be a problem especially when training on small\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
            "LSTM can also be a problem especially when training on small datasets\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step\n",
            "LSTM can also be a problem especially when training on small datasets datasets\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
            "LSTM can also be a problem especially when training on small datasets datasets translation\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
            "LSTM can also be a problem especially when training on small datasets datasets translation translation\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "LSTM can also be a problem especially when training on small datasets datasets translation translation sentiment\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "LSTM can also be a problem especially when training on small datasets datasets translation translation sentiment analysis\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "LSTM can also be a problem especially when training on small datasets datasets translation translation sentiment analysis analysis\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
            "LSTM can also be a problem especially when training on small datasets datasets translation translation sentiment analysis analysis analysis\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "LSTM can also be a problem especially when training on small datasets datasets translation translation sentiment analysis analysis analysis words\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "LSTM can also be a problem especially when training on small datasets datasets translation translation sentiment analysis analysis analysis words tasks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#General Method for testing\n",
        "def Predict(text):\n",
        "  for i in range(5):\n",
        "    #tokenize\n",
        "    token_text=tokenizer.texts_to_sequences([text])\n",
        "    #token_text[0]\n",
        "    #Padding\n",
        "    padded_token_text=pad_sequences(token_text,maxlen=max_len,padding='pre')\n",
        "    #padded_token_text\n",
        "    #Predict\n",
        "    arg=np.argmax(model.predict(padded_token_text)[0])\n",
        "    for word,index in tokenizer.word_index.items():\n",
        "      if index==arg:\n",
        "        text=text+' '+word\n",
        "        print(text)\n",
        "        break"
      ],
      "metadata": {
        "id": "SZdmiiQxy7yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing for Words in the provided text and also out of the text\n",
        "Words=['forget gate','gate','Overfitting','Overfitting problem','LSTM','memory']\n",
        "for word in Words:\n",
        "  print(word)\n",
        "  Predict(word)\n",
        "  print('\\n*************************************************************\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBHQgKCnDD7O",
        "outputId": "b1b5df1f-854c-4da3-bdd9-caa22d5fb68c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forget gate\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
            "forget gate gates\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "forget gate gates in\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "forget gate gates in an\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
            "forget gate gates in an lstm\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
            "forget gate gates in an lstm control\n",
            "\n",
            "*************************************************************\n",
            "\n",
            "gate\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
            "gate gates\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
            "gate gates include\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
            "gate gates include the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
            "gate gates include the forget\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
            "gate gates include the forget gate\n",
            "\n",
            "*************************************************************\n",
            "\n",
            "Overfitting\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
            "Overfitting can\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
            "Overfitting can also\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
            "Overfitting can also be\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
            "Overfitting can also be a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
            "Overfitting can also be a problem\n",
            "\n",
            "*************************************************************\n",
            "\n",
            "Overfitting problem\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
            "Overfitting problem transformer\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
            "Overfitting problem transformer transformer\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
            "Overfitting problem transformer transformer models\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
            "Overfitting problem transformer transformer models which\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
            "Overfitting problem transformer transformer models which use\n",
            "\n",
            "*************************************************************\n",
            "\n",
            "LSTM\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
            "LSTM can\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "LSTM can also\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
            "LSTM can also be\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "LSTM can also be a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "LSTM can also be a problem\n",
            "\n",
            "*************************************************************\n",
            "\n",
            "memory\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "memory shortterm\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "memory shortterm memory\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "memory shortterm memory lstm\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "memory shortterm memory lstm networks\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "memory shortterm memory lstm networks are\n",
            "\n",
            "*************************************************************\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Its working good even though we have very less data! And for the input \"Overfitting Problem\" it understands the semantic and Predicts Transformers!!!"
      ],
      "metadata": {
        "id": "Bjix-vAFDHBx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}