{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. re (Regular Expressions): Helps in pattern matching and text preprocessing.\n",
    "2. sklearn.utils.shuffle: Randomly shuffles datasets to avoid biases in training.\n",
    "3. tensorflow.keras.layers:\n",
    "    1. Input: Defines input layers for neural networks.\n",
    "    2. LSTM: Long Short-Term Memory layer for sequential data processing (e.g., NLP).\n",
    "    3. Embedding: Converts categorical data into dense vector representations.\n",
    "    4. Dense: Fully connected layer for deep learning models.\n",
    "    5. Bidirectional: Wraps LSTM to process input in both forward and backward directions.\n",
    "4. tensorflow.keras.models.Model: Defines and compiles deep learning models.\n",
    "5. string & digits (from string module): Used for string operations, including handling punctuation and digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input,LSTM,Embedding,Dense,Bidirectional\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r'C:\\Users\\User\\Downloads\\Dataset_English_Hindi.csv\\Dataset_English_Hindi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Help!</td>\n",
       "      <td>बचाओ!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jump.</td>\n",
       "      <td>उछलो.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jump.</td>\n",
       "      <td>कूदो.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jump.</td>\n",
       "      <td>छलांग.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello!</td>\n",
       "      <td>नमस्ते।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English    Hindi\n",
       "0   Help!    बचाओ!\n",
       "1   Jump.    उछलो.\n",
       "2   Jump.    कूदो.\n",
       "3   Jump.   छलांग.\n",
       "4  Hello!  नमस्ते।"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us analyze the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English\n",
       "False    130474\n",
       "True          2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['English'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hindi\n",
       "False    130164\n",
       "True        312\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Hindi'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert everything into LOWER case\n",
    "data.English=data.English.apply(lambda x: x.lower())\n",
    "data.Hindi=data.Hindi.apply(lambda x: x.lower())\n",
    "\n",
    "# Remove Quotes\n",
    "data.English=data.English.apply(lambda x: re.sub(\"'\",'',x))\n",
    "data.Hindi=data.Hindi.apply(lambda x: re.sub(\"'\",'',x))\n",
    "\n",
    "# Set of all special characters\n",
    "exclude=set(string.punctuation)\n",
    "\n",
    "# Remove all Special characters stored in the above set 'exclude'\n",
    "data.English=data.English.apply(lambda x:''.join(ch for ch in x if ch not in exclude))\n",
    "data.Hindi=data.Hindi.apply(lambda x:''.join(ch for ch in x if ch not in exclude))\n",
    "\n",
    "#Removing Hindi punctuations explicitly\n",
    "hindi_punctuation = '।॥“”‘’'\n",
    "data.Hindi = data.Hindi.apply(lambda x: re.sub(f\"[{hindi_punctuation}]\", \"\", x))\n",
    "\n",
    "\n",
    "# Remove all numbers from the text\n",
    "remove_digits=str.maketrans('','',digits)#creates a translation table that removes all digits (0-9) from a string when used with .translate().\n",
    "data.English=data.English.apply(lambda x: x.translate(remove_digits))\n",
    "data.Hindi = data.Hindi.apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "\n",
    "# Remove all extra spaces\n",
    "data.English=data.English.apply(lambda x: x.strip())\n",
    "data.Hindi=data.Hindi.apply(lambda x: x.strip())\n",
    "data.English=data.English.apply(lambda x : re.sub(' +',' ',x))\n",
    "data.Hindi=data.Hindi.apply(lambda x : re.sub(' +',' ',x))\n",
    "\n",
    "data.Hindi=data.Hindi.apply(lambda x: 'START_+ '+x+' _END')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Preprocessing Summary\n",
    "1. Lowercasing – Converts all text to lowercase.\n",
    "2. Remove Quotes & Special Characters – Eliminates punctuation and single quotes.\n",
    "3. Remove Numbers – Deletes English digits (0-9) and specific Hindi numerals.\n",
    "4. Remove Extra Spaces – Strips leading/trailing spaces and replaces multiple spaces with a single one.\n",
    "5. Add Start & End Tokens (Hindi) – Wraps Hindi text with \"START_+ \" and \" _END\" for sequence modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51215</th>\n",
       "      <td>history</td>\n",
       "      <td>START_+ इतिहास _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13617</th>\n",
       "      <td>january nd</td>\n",
       "      <td>START_+ जनवरी में _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78505</th>\n",
       "      <td>given below are the names of the speakers or p...</td>\n",
       "      <td>START_+ जो प्रतिष्ठित व्यक़्ति अध्यक्ष पद पर य...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42106</th>\n",
       "      <td>english govt has not approved the order</td>\n",
       "      <td>START_+ अंग्रेज़ सरकार ने यह मांग पूरी नहीं की...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99618</th>\n",
       "      <td>the hair of the body are jet black and lustrous</td>\n",
       "      <td>START_+ शरीर के बाल गहरे काले और चमकीले होते ह...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 English  \\\n",
       "51215                                            history   \n",
       "13617                                         january nd   \n",
       "78505  given below are the names of the speakers or p...   \n",
       "42106            english govt has not approved the order   \n",
       "99618    the hair of the body are jet black and lustrous   \n",
       "\n",
       "                                                   Hindi  \n",
       "51215                                START_+ इतिहास _END  \n",
       "13617                             START_+ जनवरी में _END  \n",
       "78505  START_+ जो प्रतिष्ठित व्यक़्ति अध्यक्ष पद पर य...  \n",
       "42106  START_+ अंग्रेज़ सरकार ने यह मांग पूरी नहीं की...  \n",
       "99618  START_+ शरीर के बाल गहरे काले और चमकीले होते ह...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole vocabulary of Hindi and English present in the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English Vocabulary\n",
    "english_vocab = set()\n",
    "for sentence in data.English:\n",
    "    for word in sentence.split():\n",
    "        english_vocab.add(word)  # No need for the extra 'if' check\n",
    "\n",
    "# Hindi Vocabulary\n",
    "hindi_vocab = set()\n",
    "for sentence in data.Hindi:\n",
    "    for word in sentence.split():\n",
    "        hindi_vocab.add(word)  # No need for the extra 'if' check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max Length of Source sequence\n",
    "length_list=[]\n",
    "for l in data.English:\n",
    "    length_list.append(len(l.split(' ')))\n",
    "max_length_src=np.max(length_list)\n",
    "\n",
    "# Max Length of Target sequence\n",
    "length_list=[]\n",
    "for l in data.Hindi:\n",
    "    length_list.append(len(l.split(' ')))\n",
    "max_length_tar=np.max(length_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_words=sorted(list(english_vocab))\n",
    "target_words=sorted(list(hindi_vocab))\n",
    "\n",
    "num_encoder_tokens=len(english_vocab)\n",
    "num_decoder_tokens=len(hindi_vocab)\n",
    "num_encoder_tokens,num_decoder_tokens\n",
    "\n",
    "# for 0 padding\n",
    "num_decoder_tokens+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84207"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index=dict([word,i+1] for i,word in enumerate(input_words))\n",
    "target_token_index=dict([word,i+1] for i,word in enumerate(target_words))\n",
    "\n",
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27053\n",
      "28551\n",
      "2279\n",
      "35181\n",
      "64814\n"
     ]
    }
   ],
   "source": [
    "for i in ['hello','i','am','learning','translation']:\n",
    "    print(input_token_index[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86628</th>\n",
       "      <td>the system of opening banks in villages by the...</td>\n",
       "      <td>START_+ ग्रमीण बैंकों के खुलने से इस उपराध से ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28132</th>\n",
       "      <td>harvest baby teeth</td>\n",
       "      <td>START_+ दूध के दाँतों की फसल काट लो _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115272</th>\n",
       "      <td>the northern face of the rock is roughly carve...</td>\n",
       "      <td>START_+ चट्टान के उत्तरी फलक पर एक बड़े बैठे ह...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109362</th>\n",
       "      <td>australia has received its first championship ...</td>\n",
       "      <td>START_+ ऑस्ट्रेलिया ने अपनी राष्ट्रीय प्रथम श्...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38569</th>\n",
       "      <td>lrb pradeep jain v union of india air sc scc rrb</td>\n",
       "      <td>START_+ प्रदीप जैन बनाम भारत संघ ए आई आर 1984 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  English  \\\n",
       "86628   the system of opening banks in villages by the...   \n",
       "28132                                  harvest baby teeth   \n",
       "115272  the northern face of the rock is roughly carve...   \n",
       "109362  australia has received its first championship ...   \n",
       "38569    lrb pradeep jain v union of india air sc scc rrb   \n",
       "\n",
       "                                                    Hindi  \n",
       "86628   START_+ ग्रमीण बैंकों के खुलने से इस उपराध से ...  \n",
       "28132            START_+ दूध के दाँतों की फसल काट लो _END  \n",
       "115272  START_+ चट्टान के उत्तरी फलक पर एक बड़े बैठे ह...  \n",
       "109362  START_+ ऑस्ट्रेलिया ने अपनी राष्ट्रीय प्रथम श्...  \n",
       "38569   START_+ प्रदीप जैन बनाम भारत संघ ए आई आर 1984 ...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=shuffle(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as pickle\n",
    "with open(\"preprocessed_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to load the preprocessed data stored as pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86628</th>\n",
       "      <td>the system of opening banks in villages by the...</td>\n",
       "      <td>START_+ ग्रमीण बैंकों के खुलने से इस उपराध से ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28132</th>\n",
       "      <td>harvest baby teeth</td>\n",
       "      <td>START_+ दूध के दाँतों की फसल काट लो _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115272</th>\n",
       "      <td>the northern face of the rock is roughly carve...</td>\n",
       "      <td>START_+ चट्टान के उत्तरी फलक पर एक बड़े बैठे ह...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109362</th>\n",
       "      <td>australia has received its first championship ...</td>\n",
       "      <td>START_+ ऑस्ट्रेलिया ने अपनी राष्ट्रीय प्रथम श्...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38569</th>\n",
       "      <td>lrb pradeep jain v union of india air sc scc rrb</td>\n",
       "      <td>START_+ प्रदीप जैन बनाम भारत संघ ए आई आर 1984 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  English  \\\n",
       "86628   the system of opening banks in villages by the...   \n",
       "28132                                  harvest baby teeth   \n",
       "115272  the northern face of the rock is roughly carve...   \n",
       "109362  australia has received its first championship ...   \n",
       "38569    lrb pradeep jain v union of india air sc scc rrb   \n",
       "\n",
       "                                                    Hindi  \n",
       "86628   START_+ ग्रमीण बैंकों के खुलने से इस उपराध से ...  \n",
       "28132            START_+ दूध के दाँतों की फसल काट लो _END  \n",
       "115272  START_+ चट्टान के उत्तरी फलक पर एक बड़े बैठे ह...  \n",
       "109362  START_+ ऑस्ट्रेलिया ने अपनी राष्ट्रीय प्रथम श्...  \n",
       "38569   START_+ प्रदीप जैन बनाम भारत संघ ए आई आर 1984 ...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "# Load it back\n",
    "with open(\"preprocessed_data.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['inp_len']=data.English.apply(lambda x:len(x.split()))\n",
    "data['tar_len']=data.Hindi.apply(lambda x:len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Hindi</th>\n",
       "      <th>inp_len</th>\n",
       "      <th>tar_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76367</th>\n",
       "      <td>need to be accompanied by a mystical feeling</td>\n",
       "      <td>START_+ किसी आध्यात्मिक भावना से जोडा जाये _END</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95640</th>\n",
       "      <td>thereafter the approximate age can be determin...</td>\n",
       "      <td>START_+ इसके बाद तो आयु का अनुमान दांतों के घि...</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83403</th>\n",
       "      <td>the effect of the morphine injection lasts jus...</td>\n",
       "      <td>START_+ मॉर्फीन इंजेक्शन का असर चार घंटे रहता ...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42348</th>\n",
       "      <td>i nearly died was in a coma</td>\n",
       "      <td>START_+ मै लगभग मर गयी थी कोमा में थी _END</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121535</th>\n",
       "      <td>halva type of sweet</td>\n",
       "      <td>START_+ लप्सी _END</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  English  \\\n",
       "76367        need to be accompanied by a mystical feeling   \n",
       "95640   thereafter the approximate age can be determin...   \n",
       "83403   the effect of the morphine injection lasts jus...   \n",
       "42348                         i nearly died was in a coma   \n",
       "121535                                halva type of sweet   \n",
       "\n",
       "                                                    Hindi  inp_len  tar_len  \n",
       "76367     START_+ किसी आध्यात्मिक भावना से जोडा जाये _END        8        8  \n",
       "95640   START_+ इसके बाद तो आयु का अनुमान दांतों के घि...       17       26  \n",
       "83403   START_+ मॉर्फीन इंजेक्शन का असर चार घंटे रहता ...       10       10  \n",
       "42348          START_+ मै लगभग मर गयी थी कोमा में थी _END        7       10  \n",
       "121535                                 START_+ लप्सी _END        4        3  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((91113,), (39049,))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y=data.English,data.Hindi\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_pickle('X_train.pkl')\n",
    "X_test.to_pickle('X_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X=X_train,y=y_train,batch_size=128):\n",
    "    '''Method to Generate a Batch of Data'''\n",
    "    # default batch size=128\n",
    "    for j in range(0,len(X),128):\n",
    "        encoder_input_data=np.zeros((batch_size,max_length_src),dtype='float32')\n",
    "        decoder_input_data=np.zeros((batch_size,max_length_tar),dtype='float32')\n",
    "        decode_target_data=np.zeros((batch_size,max_length_tar,num_decoder_tokens),dtype='float32')\n",
    "\n",
    "        for i,(input_text,target_text) in enumerate(zip(X[j:j+batch_size],y[j:j+batch_size])):\n",
    "            \n",
    "            for t,word in enumerate(input_text.split()):\n",
    "                encoder_input_data[i,t]=input_token_index[word]\n",
    "            for t,word in enumerate(target_text.split()):\n",
    "                if(t<len(target_text.split())-1):\n",
    "                    decoder_input_data[i,t]=target_token_index[word]\n",
    "                    #Decoder input sequence for -\n",
    "                    '''Teacher Forcing'''\n",
    "                if(t>0):\n",
    "                    #decoder target sequence OHE\n",
    "                    #It doesn't include the START token\n",
    "                    # therefore, Offset by 1 timestep\n",
    "                    decoder_target_data[i,t-1,target_token_index[word]]=1\n",
    "        yield([encoder_input_data, decoder_input_data],decoder_target_data)      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder\n",
    "encoder_inputs=Input(shape=(None,))\n",
    "enc_emb=Embedding(input_dim=num_encoder_tokens,output_dim=latent_dim,mask_zero=True)(encoder_inputs)\n",
    "encoder_lstm=LSTM(units=latent_dim, return_state=True)\n",
    "encoder_outputs,state_h,state_c=encoder_lstm(enc_emb)\n",
    "#We only need the states of the encoder\n",
    "encoder_states=[state_h,state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder using 'encoder_states' as initial state\n",
    "decoder_inputs=Input(shape=(None,))\n",
    "decoder_emb_layer=Embedding(input_dim=num_decoder_tokens,output_dim=latent_dim,mask_zero=True)\n",
    "#By mask_zero = True, the model will ignore the 0s as it has 0 contribution in the target sentence\n",
    "dec_emb=decoder_emb_layer(decoder_inputs)\n",
    "'''We set up our decoder to return full output sequences, \n",
    "and to return internal states as well. We don't use the\n",
    "return states in the training model but we will use \n",
    "it for inference'''\n",
    "decoder_lstm=LSTM(units=latent_dim,return_sequences=True,return_state=True)\n",
    "decoder_outputs,_,_=decoder_lstm(dec_emb,initial_state=encoder_states)\n",
    "decoder_dense=Dense(units=num_decoder_tokens,activation='softmax')\n",
    "decoder_outputs=decoder_dense(decoder_outputs)\n",
    "\n",
    "''' Define the model that will turn 'encoder_input_data' &\n",
    "'decoder_input_data' to 'decoder_target_data' '''\n",
    "\n",
    "model=Model([encoder_inputs,decoder_inputs],decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid keyword argument(s) in `compile()`: ({'optimmizer'},). Valid keyword arguments include \"cloning\", \"experimental_run_tf_function\", \"distribute\", \"target_tensors\", or \"sample_weight_mode\".",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimmizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategorical_crossentropy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\DeepLeanring\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\User\\DeepLeanring\\.venv\\lib\\site-packages\\keras\\engine\\training.py:3524\u001b[0m, in \u001b[0;36mModel._validate_compile\u001b[1;34m(self, optimizer, metrics, **kwargs)\u001b[0m\n\u001b[0;32m   3522\u001b[0m invalid_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(kwargs) \u001b[38;5;241m-\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m   3523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m invalid_kwargs:\n\u001b[1;32m-> 3524\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   3525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid keyword argument(s) in `compile()`: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3526\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(invalid_kwargs,)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Valid keyword arguments include \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3527\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcloning\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperimental_run_tf_function\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistribute\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   3528\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, or \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   3529\u001b[0m     )\n\u001b[0;32m   3531\u001b[0m \u001b[38;5;66;03m# Model must be created and compiled with the same DistStrat.\u001b[39;00m\n\u001b[0;32m   3532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;129;01mand\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mhas_strategy():\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid keyword argument(s) in `compile()`: ({'optimmizer'},). Valid keyword arguments include \"cloning\", \"experimental_run_tf_function\", \"distribute\", \"target_tensors\", or \"sample_weight_mode\"."
     ]
    }
   ],
   "source": [
    "model.compile(optimmizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
